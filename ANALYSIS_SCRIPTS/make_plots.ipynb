{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shared_data as sd\n",
    "import utility_functions as uf\n",
    "from config_file_utils import ConfigFile\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m cf \u001b[39m=\u001b[39m ConfigFile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msd\u001b[39m.\u001b[39mCONFIG_FILES_DIR\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mconfig_file_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m y \u001b[39m=\u001b[39m uf\u001b[39m.\u001b[39mget_y(\n\u001b[1;32m      6\u001b[0m     sd\u001b[39m.\u001b[39mPARTITION_N_TRJS,\n\u001b[1;32m      7\u001b[0m     sd\u001b[39m.\u001b[39mTRJ_LEN,\n\u001b[1;32m      8\u001b[0m     \u001b[39mlen\u001b[39m(sd\u001b[39m.\u001b[39mPAIRS[cf\u001b[39m.\u001b[39mpair_name]),\n\u001b[1;32m      9\u001b[0m     cf\u001b[39m.\u001b[39mconfig_dict\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m y_predicted \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(glob(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m*validation_\u001b[39;49m\u001b[39m{\u001b[39;49;00mcf\u001b[39m.\u001b[39;49mconfig_index\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m     12\u001b[0m accuracy_mean, accuracy_sem \u001b[39m=\u001b[39m uf\u001b[39m.\u001b[39mget_accuracy_mean_and_sem(y_predicted, y, cf, \u001b[39m2\u001b[39m)\n\u001b[1;32m     13\u001b[0m pipeline_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcf\u001b[39m.\u001b[39mdim_reduction_name\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mcf\u001b[39m.\u001b[39mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ERMDL_ENV/lib/python3.9/site-packages/numpy/lib/npyio.py:416\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39m(os_fspath(file), \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    417\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not list"
     ]
    }
   ],
   "source": [
    "accuracy_mean_dict = defaultdict(dict)\n",
    "annot_dict = defaultdict(dict)\n",
    "for config_file_name in os.listdir(sd.CONFIG_FILES_BEST_DIR):\n",
    "    cf = ConfigFile(f\"{sd.CONFIG_FILES_DIR}/{config_file_name}\")\n",
    "    y = uf.get_y(\n",
    "        sd.PARTITION_N_TRJS,\n",
    "        sd.TRJ_LEN,\n",
    "        len(sd.PAIRS[cf.pair_name]),\n",
    "        cf.config_dict\n",
    "    )\n",
    "    y_predicted = np.load(glob(f\"*validation_{cf.config_index}\"))\n",
    "    accuracy_mean, accuracy_sem = uf.get_accuracy_mean_and_sem(y_predicted, y, cf, 2)\n",
    "    pipeline_name = f\"{cf.dim_reduction_name}/{cf.model_name}\"\n",
    "    accuracy_mean_dict[cf.pair_name][pipeline_name][cf.sel_name] = accuracy_mean\n",
    "    annot_dict[cf.pair_name][pipeline_name][cf.sel_name] = f\"{accuracy_mean:.2f}\\n\\u00B1\\n{accuracy_sem:.2f}\"\n",
    "for pair_name in sd.PAIRS:\n",
    "    accuracy_mean_df = pd.DataFrame(accuracy_mean_dict[pair_name])\n",
    "    annot_df = pd.DataFrame(annot_dict[pair_name])\n",
    "    plt.figure(figsize=(20, 9))\n",
    "    plt.title(f\"Classification model comparison for {pair_name}\")\n",
    "    sns.heatmap(\n",
    "        X=accuracy_mean_df, \n",
    "        vmin=0.5, \n",
    "        vmax=1, \n",
    "        cmap=\"RdBu\", \n",
    "        annot=annot_df,\n",
    "        fmt=\"\",\n",
    "        xticklabels=list(accuracy_mean_df.index),\n",
    "        yticklabels=list(accuracy_mean_df.columns),\n",
    "        cbar_kws={\"label\": \"Cross validation accuracy\", \"pad\": 0.01},\n",
    "    )\n",
    "    plt.xticks(rotation=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ERMDL_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
